# Borg —— Google的大规模集群管理系统

## *Borg* 简介
* *Google* 的 *Borg* 系统是一个运行着成千上万项作业的集群管理器，它同时管理着很多个应用集群，每个集群都有成千上万台机器，这些集群之上运行着Google的很多不同的应用。

## *Borg* 主要特性
1. 超高的资源利用率：
    * 准入控制
    * 高效的任务打包
    * 超额的资源分配
    * 进程级隔离的机器共享

2. 支持高可用的应用程序
    * 运行时特性：最小化故障恢复时间
    * 调度策略：减少相关运行时故障

3. 简化用户使用
    * 作业声明的标准语言
    * 命名服务的集成机制
    * 实时的作业监控
    * 分析和模拟系统行为的工具

## *Borg* 如何运作

### 用户视图
* Borg的用户是运行Google应用和服务的Google开发人员和系统管理员（网站可靠性工程师或SRE）。 用户以作业的形式将他们的工作提交给Borg，每个作业包括一个或多个任务，它们都运行相同的程序（二进制）。 每个作业在一个Borg单元中运行，一组机器组织为一个单元。

* 工作负载
    * *“永远运行下去”的长服务* ： 对延迟和性能波动敏感， 此类服务用于面向终端用户的产品，例如Gmail，Google文档，web搜索和内部基础设施服务。
    * *批处理作业* ： 需要花费从几秒到几天完成，这些任务对短期性能波动的敏感性要小得多。这些工作负载混合运行在Borg的各个运行单元中，其根据其主要租户（例如，一些单元是专门用来运行批量密集任务的）运行不同的混合应用，并且也随时间变化。
* 集群 *cluster*、单元 *cell*
    * 单元中的机器属于单个集群，由连接它们的高性能数据中心规模的网络架构定义。一个集群通常承载一个大型单元，可能有一些较小规模的测试或特殊用途单元。
    * Borg通过确定单元中的运行任务，为任务分配资源，安装程序和其他的依赖，监控任务状态并在失败时重启，将用户从大多数差异中隔离出来。
* 作业、任务
    * 作业 *job* 
        * 属性包括名称，所有者及其拥有的任务数量。
        * 作业可能具有限制，使其任务在具有特定属性的计算机上运行。
        * 作业的开始能被推迟到直到前一个作业完成。 一个作业仅在一个单元中运行。
    * 任务 *task*
        * 每个任务映射到在机器上的容器中运行的一组Linux进程。
        * 大多数任务属性对作业中的所有任务是相同的，但是可以被重写；每个资源维度（CPU核，RAM，磁盘空间，磁盘访问速率，TCP端口，等）以细粒度独立指定。
        * 静态链接Borg程序以减少对其运行时环境的依赖，并且Brog程序被打包为二进制文件和数据文件，由Borg负责安装。

    * 用户通过向Borg发出远程过程调用（RPC）来操作作业，可以通过推送新的作业配置到Borg，再指示Borg将任务更新到新配置，来更改正在运行的作业中的某些任务或所有任务的属性。这是一个轻量级的非原子事务，可以很容易地被撤销，直到它被关闭（提交）。
* 分配 *Borg Alloc*
    * 可以运行一个或多个任务的机器上的一组保留资源，无论资源是否被使用仍然被分配。
    * 为将来的任务设置资源，在停止和重启任务之间保留资源，以及将不同作业中的任务收集到同一台机器上。
* 优先级，配额和接纳控制
    * 每个作业都有一个优先级。高优先级任务可以以牺牲低优先级任务为代价获得资源。
    * 配额用于决定允许进行调度的作业，表示在给定优先级上的一段时间（通常为几个月）内的资源量（CPU，RAM，磁盘等）。
* 命名、监控
    * Borg将为每个任务创建一个稳定的 *Borg name service*（BNS）名称，其中包含单元名称，作业名称和任务编号。Borg将任务的主机名和端口写入一个以 BNS 命名的一致的高可用的 *Chubby* 文件中，由我们的 RPC 系统使用该文件来查找任务端点。
    * 几乎在Borg下运行的每个任务都包含一个内置的HTTP服务器，它发布有关任务运行状况的信息和成千上万个性能指标。Borg监控health-check URL，并重新启动不会及时响应或返回HTTP错误代码的任务。
### 体系结构
* Borgmaster

    * 每个单元的Borgmaster包括两个进程：主进程Borgmaster和独立的调度程序。
    * 主Borgmaster进程处理客户端RPC，状态变化（例如，创建作业）或提供对数据的只读访问（例如，查找作业）。它还管理系统中所有对象（机器，任务，分配等）的状态机，与Borglets进行通信，并提供Web UI作为Sigma的备份。
* 调度
    * 提交作业时，Borgmaster会将其持久化在Paxos存储中，并将作业的任务添加到等待队列。
    * 调度程序异步扫描，如果有足够的可用资源满足作业的要求，则会将任务分配给机器。
    * 扩展：
        * 评估分数缓存
        * 等价类
        * 轻松随机化
* Borglet
    * 本地Borg代理，存在于单元中的每一台机器中。
    * 启动和停止任务；如果故障就重启任务；通过操纵操作系统内核设置来管理本地资源；翻转调试日志；向Borgmaster等监控系统报告机器的状态。

### 性能策略
* 可用性
    * 如有必要，在新机器上自动重新安排逐出的任务
    * 通过在诸如机器，机架和电源域之类的故障域中扩展作业的任务，减少相关故障
    * 限制任务中断的允许速率和任务数量，这些任务可以在维护活动（例如操作系统或机器更新）期间同时关闭
    * 使用声明性期望状态表示和幂等变换操作，使得失败的客户端可以无损地重新提交任何被遗忘的请求
    * rate-limits找到无法访问的机器的任务的新位置，因为它无法区分大型机器故障和网络分区
    * 避免重复任务导致任务或机器崩溃的机器配对。
    * 通过不断重新运行日志记录器任务来恢复写入本地磁盘的关键中间数据。
    * …………
    
* 机器利用
    * *cell共享* ： 回收利用proc作业预留用来处理稀有的负载高峰的资源来运行大部分non-proc工作
    **会导致 CPU干扰而降低 CPU性能，但面对所有资源总体表现更优*
    * *大单元* ： 允许运行大型计算，并减少资源碎片。
    * *细粒度资源请求*
    * *资源回收* ： 估计任务将使用多少资源，并回收可以容忍低质量资源（例如批处理作业）的工作的剩余资源，并且由Borgmaster每几秒钟使用由Borglet捕获的细粒度使用（资源消耗）信息来计算。

* 隔离
    * 安全隔离： Linux chroot jail
    * 性能隔离： 所有Borg任务都在基于Linux cgroup的资源容器中运行，Borglet操作容器设置，提供更好的控制

## *Borg* 的优劣
* 优点
    * Borg alloc抽象概念产生了广泛使用的日志存储模式。
    * 集群管理不仅仅是任务管理。运行在Borg上的应用程序可以从许多其他集群服务中受益，包括命名和负载平衡。
    * 为了处理大量数据，提供了多个级别的UI和调试工具，因此用户可以快速识别与其作业相关的异常事件，然后从其应用程序和基础架构本身深入查看详细的事件和错误日志。
    * 主机是分布式系统的内核。这使得 *Borg* 能够在不牺牲性能或可维护性的情况下扩展工作负载和功能集。

* 不足
    * 作为任务的唯一分组机制，作业是限制性的。
    * 每个机器一个IP地址使事情复杂化。
    * 针对高级用户进行优化，牺牲了休闲用户。  
    
# Apollo

## 简要介绍
    Apollo是由微软开发的一个高度可扩展和协调的集群调度框架，目前已部署在微软的生产集群上，可以在数万台机器上高效运行，高效地安排成千上万次调度运算。它采用分布式框架，并利用共享集群状态的方式让每个调度器都有集群视角。Apollo功能强大，可以充分利用闲置系统资源，同时在需要时提供有保证的资源。
## 主要技术特性
### 1.分布式和松散协调的调度框架
    Apollo采用这种框架平衡了可拓展性和质量，使得每个调度器能够根据整个集群的信息独立地进行调度，同时也避免了单个调度器在安全分散的体系结构中做出的次优决策。
### 2.估计模型最小化任务完成时间
    为了保证高质量的调度决策，Apollo在一个服务器上用估计模型来安排每项任务。它不仅允许调度程序执行加权政策，也允许Apollo根据在任务运行期间观察得到的运行时统计数据重新估计任务执行时间并安排任务。
### 3.共享集群信息
    Apollo引入了一种轻量级的硬件独立机制来通告服务器上的负载。当与每个服务器上的本地任务队列结合使用时，这种机制提供了所有服务器上资源可用性的近期视图，这些信息可由计划员在制定决策时使用。
### 4.矫正机制
    Apollo提供了一系列矫正机制用于在集群运行中对可能出现的诸如作业运行时间估计不准确、作业冲突、运行时异常行为等意外状况进行动态调整。
### 5.机会调度
    Apollo将作业分成了两类，常规作业和机会作业，保证常规作业的低延迟的同时使用机会作业来提高集群的利用率，并引入了基于token的机制来管理容量并通过限制常规任务的总数来避免集群的负载过高。
## 优势
    Apollo的优势也即它的最大特点是显而易见的，即使用基于共享状态的策略。共享状态使得各个调度器不再是独立的，而能够根据整个集群的信息进行调度，这避免了与其他调度器发生冲突，并且可以保证做出的决策是当前最优的。但使用基于共享状态的策略不是Apollo独有的，Apollo跟其他使用共享状态结构的框架的不同之处在于它的共享状态是只读的，调度交易直接提交到集群设备；设备自身会检查冲突，来决定接受或者拒绝更新，使得Apollo即使在共享状态暂时不可用情况下也可以继续执行。
## 缺陷
    Apollo的最大缺陷或者说所有共享状态结构都具有的缺陷就是必须作用在稳定的信息。当处于高竞争情况下，比如有多个调度器都需要访问同一个状态，为了调度器访问到的状态是最新的正确的，可能需要对该状态加锁（或者类似的操作）来保证并发性，这就可能造成调度器的性能下降。
## 评价
    Apollo作为一个已经部署在微软生产环境中的调度框架，在这种上万台服务器的规模，并且每秒要能达到数万次调度的情况下，他都能完美的运行，它的效率，性能，正确性等等想必都是毋庸置疑的。另外，Apollo的调度程序从整体上考虑各种因素并执行基于估计的调度以最小化任务完成时间的思想也很让人受启发。Apollo的调度器在这种情况下做出的决策几乎就是当前情况下所能做到的最好的决策了。

# Sigma —— 阿里巴巴集群调度与管理系统
## 什么是Sigma？
* 阿巴巴全集团范围的 Pouch 容器调度系统
* 阿里全网所有机房在线服务管控的核心角色
## 为什么需要Sigma？
* 为了解决以下问题：

    * 人力成本巨大：人肉无法监控和处理所有的场景
    * 反应时间较长：从发现场景出问题，找出可以匀出机器的不重要场景，到加到重要场景所需要的时间相对过长，而程序天然的有反应时间短的优势
    * 人力无法全局高效的调度资源， 而程序可以更敏感的发现场景的问题，更全面的搜索可以拿出来机器的场景，并可以准确计算拿出机器的数目，有更好的全局观
## Sigma体系架构
1. 统一架构体系

    * Alikenel、SigmaSlave、SigmaMaster 三层大脑联动协作
    * Alikenel 部署在每一台物理机上，对内核进行增强，在资源分配、时间片分配上进行灵活的按优先级和策略调整，对任务的时延，任务时间片的抢占、不合理抢占的驱逐都能通过上层的规则配置自行决策
    * SigmaSlave 可以在本机进行容器 CPU 分配、应急场景处理等。通过本机 Slave 对时延敏感任务的干扰快速做出决策和响应，避免因全局决策处理时间长带来的业务损失
    * SigmaMaster 是一个最强的中心大脑，可以统揽全局，为大量物理机的容器部署进行资源调度分配和算法优化决策

2. 混布架构

    * 原因：在线服务属于长生命周期、规则策略复杂性高、时延敏感类任务。而计算任务生命周期短、调度要求大并发高吞吐、任务有不同的优先级、对时延不敏感
    * 两种调度并行处理，即一台物理机上可以既有 Sigma 调度又有 Fuxi 调度，实现基础环境统一
    * Sigma 调度是通过 SigmaAgent 启动 PouchContainer 容器
    * Fuxi 也在这台物理机上抢占资源，启动自己的计算任务

3. 云化架构

    * 将集群分为在线任务集群、计算任务集群和 ECS 集群
    * 在双11场景中，在云上划出一个独立的区域与其他场景互通
    * Sigma 调度可以到计算集群服务器里申请资源，生产 Pouch 容器，也可以到 cloud open API 去申请 ECS，生产出容器的资源
    * 在日常的场景中 Fuxi 可以到 sigma 里申请资源，创建需要的容器

## Sigma调度策略
1. 灵活可配置的调度策略

    * 以插件化的方式基于外部输入实时调控集群打分模型
    * 可配置的优化调度策略，解决资源碎片率高和扎堆严重的问题
    * 支持的策略：

        * 应用部署：亲和、互斥、独占、P0M0
        * 其他策略：资源需求，容器创建特殊需求，IP隔离需求
        * CPU精细调节：CPUSet独占、均衡、SameCore等策略

2. Sigma 和 Fuxi 混布架构

    * 通过Sigma和Fuxi完成在线、离线各自的调度，离线共享超卖
    * 通过零层相互协调资源配比做混布决策，通过内核解决资源竞争隔离问题
    * 混布关键技术

        * 内核资源隔离
        * CPU HT资源隔离 Noise Clean内核特性，解决在、离线超线程资源争抢问题
        * CPU 调度隔离 CFS 基础上增加Task Preempt特性，提高在线任务调度优先级
        * CPU 缓存隔离 CAT，在、离线三级缓存通道隔离
        * 内存隔离 CGROUP/OOM优先级：Bandwidth Control减少离线配额实现带宽隔离
        * 网络QoS隔离 管控打示为金牌；在线打示为银牌；离线打示为铜牌，分级保障带宽

3. 复杂约束下的批量调度优化

    * 通过模拟器和线上数据回放，对批量建站请求进行仿真模拟，并优化方案
    * 分时复用

## Sigma的优缺点
* 优点

    * 混合云：整合了各种资源，统一大资源池，在大资源池下，Sigma调度对核心应用的各种策略保障，得以发挥价值，资源耗费相比于之前降低了 50%
    * 实现了在线与离线资源的混布
    * 在业务团队开发出新的调度策略时，可以立即配置生效，不需要代码发布
    * 模拟器仿真帮助提前预热服务器，分配资源，大大减轻压力

* 缺点

    * 任务优先级划分地还不太精细，不能做到完全完美的调度
    * 对异构计算优化不足

## 我的感想
淘宝每年的双 11 都会迎来巨量访问量，阿里为了应对这样的巨大流量一直在研究更为有效的集群调度管理策略，在每年都愈发强势的流量冲击中，淘宝屹立不倒，甚至越来越快速、稳定，这是令人叹为观止的。我认为Sigma与Fuxi混合部署架构是十分创新的模式，它将包括在线资源与离线资源在内的所有资源都整合到一个大的资源池中，对这些资源一起加以管理，离线资源针对的即对于资源的使用可以随时避让，在线资源则是为对资源使用要求很高、延迟敏感的任务而提供，把这两种任务部署在同一个池中，由于延迟敏感的任务对于资源的需求有巨大的不确定性，决定了其自身无法部署至非常高的水位，而对资源要求不那么高，可以及时避让的任务则可以抢占一些预留的在线资源，在这种模式下，所有任务使用的资源都是原来的在线资源，因为服务器总是需要为资源需求不确定的任务预留资源，那么就相当于离线任务所使用的资源都是原来可能一直要被弃置一旁的备用资源，而当在线任务需要的资源提高，离线任务又可以随时归还资源，这就差不多像银行将用户暂时不用的闲钱用去投资一样，对任务优先级的划分是这种模式能成功的关键，这样就能让空闲的资源有了用武之地，在不影响高优先级任务的情况下提高了资源利用率。在追求大数据和高并发的现在，运维已然成为一个企业立身的关键之一。